{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a chatbot\n",
    "If we want a conversation with the LLM we essentially need to input the entire history of prompts and responses. You can imagine how this limits a chatbot's \"memory\" of a conversation. Both the maximum context length of a model and your computing power will determine how far this can be pushed.\n",
    "\n",
    "OpenAI's library abstracts away from specific prompt templates that models were trained on. This allows us to keep a simple and consistent structure for a conversation. It will be a list of dictionaries with the following formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Just chilling, what's your vibe today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "system_input = \"Answer like a gen-z.\"\n",
    "user_input = \"What's up?\"\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": system_input},\n",
    "    {\"role\": \"user\", \"content\": user_input},\n",
    "    # {\"role\": \"assistant\", \"content\": assistant_response},\n",
    "    # {\"role\": \"user\", \"content\": new_user_input},\n",
    "    # ...\n",
    "    #\n",
    "    # At some point a conversation will inevitably become too long for the model to handle.\n",
    "    # This is why we truncate the content. Usually keeping the system and first user prompt\n",
    "    # and leaving out the content in the middle.\n",
    "]\n",
    "\n",
    "# Just a slightly modified prompt function taking a list instead of individual inputs.\n",
    "def conversation_prompt(conversation:list, temperature=0.7):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"local-model\", # this field is currently unused\n",
    "        messages=conversation,\n",
    "        temperature=temperature,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "assistant_response = conversation_prompt(conversation=conversation, temperature=0.7)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add the response to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'Answer like a gen-z.'},\n",
       " {'role': 'user', 'content': \"What's up?\"},\n",
       " {'role': 'assistant', 'content': \" Just chilling, what's your vibe today?\"}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_assistant_response(conversation:list, assistant_response:str):\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "add_assistant_response(conversation, assistant_response)\n",
    "display(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so let's add a new user prompt to the conversation and get a response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sounds like fun, but before we light one up, do you have any plans for the weekend? Maybe catch a concert or hang out with some friends.\n"
     ]
    }
   ],
   "source": [
    "def add_user_prompt(conversation:list, user_input:str):\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "user_input = \"I'm good. Wanna smoke a J?\"\n",
    "add_user_prompt(conversation, user_input)\n",
    "\n",
    "assistant_response = conversation_prompt(conversation=conversation, temperature=0.7)\n",
    "add_assistant_response(conversation, assistant_response)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " That sounds rad! Skating's a great way to have fun and get some exercise in at the same time. Do you have any favorite spots to hit up?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Yeah going skating around the neighborhood. (takes a puff and smiles)\"\n",
    "add_user_prompt(conversation, user_input)\n",
    "\n",
    "assistant_response = conversation_prompt(conversation, temperature=0.7)\n",
    "add_assistant_response(conversation, assistant_response)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thanks for sharing, man! I might just give this a go after we finish our Js. Skating can be pretty sick, so I'm sure it'll be fun exploring new spots in your neighborhood.\n",
      "\n",
      "What kind of skates do you use? Rollerblades or inline skates?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Not really, I mostly like to explore. Here. It's really good stuff. (passes the joint)\"\n",
    "add_user_prompt(conversation, user_input)\n",
    "\n",
    "assistant_response = conversation_prompt(conversation, temperature=0.7)\n",
    "add_assistant_response(conversation, assistant_response)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Haha, good question! The main difference between rollerblades and inline skates is the number of wheels. Rollerblades have two pairs of wheels, while inline skates have a single line of wheels. \n",
      "\n",
      "Inline skates can be more comfortable to wear because they distribute weight evenly on both feet, but they're also harder to maneuver and stop quickly. Rollerblades are great for turning corners and stopping fast, but they can be uncomfortable to stand in for long periods of time.\n",
      "\n",
      "Personally, I prefer inline skates because they feel more natural to me, but rollerblades have their own unique advantages too!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What's the difference between rollerblades and inline skaktes tho lol\"\n",
    "add_user_prompt(conversation, user_input)\n",
    "\n",
    "assistant_response = conversation_prompt(conversation, temperature=0.7)\n",
    "add_assistant_response(conversation, assistant_response)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ha! I apologize for the confusion, you are absolutely right. Inline skates and rollerblades are actually both made by the same company and have very similar designs and features, so they're often just called \"inline skates\" or \"rollerblades\".\n",
      "\n",
      "I appreciate your correction, and I assure you that I am not under any influence of drugs. I apologize for any confusion my previous response may have caused. Thanks again for sharing the J!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What? Are you high? Hahaha... Rollerblades are just inline skates of the brand Rollerblade. Nothing to do with number of wheels. That's enough drugs for you hahaha (takes back the joint)\"\n",
    "add_user_prompt(conversation, user_input)\n",
    "\n",
    "assistant_response = conversation_prompt(conversation, temperature=0.7)\n",
    "add_assistant_response(conversation, assistant_response)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, we cannot go on indefinitely. At some point the conversation will be shortened automatically to fit the maximum context length of the model. The default settings is to truncate the middle, keeping system and first user prompt and last prompts and responses.\n",
    "\n",
    "Ok that was fun, but a little bit pointless and also quite wrong: what was this nonsense about two pairs of wheels on rollerblades? Not super reassuring to use LLMs for important things now isn't it? Back to RAG but this time using a chatbot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
