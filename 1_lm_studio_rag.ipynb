{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG with LM Studio and OpenAI Client\n",
    "LM Studio allows us to use many foundation models and fine-tuned version thereof on less powerful hardware. It also provides quatitized versions which have lower precision weights and biases and run much more efficiently at a small performance cost.\n",
    "\n",
    "Open LM Studio, download a model of your choice (within your computing power) and start a server in the Local Server tab. Once you started a server in LM Studio a log will be available to observe the process of generation in real-time. \n",
    "\n",
    "The following examples were made using the `mistral instruct v0 1 7B Q3_K_S gguf` model originally from `Mistral AI` and provided in GGUF format by `TheBloke`.\n",
    "\n",
    "Let's start by instantiating the OpenAI client that will be communicating with LM Studio server. You can also see how the prompt function is just a wrapper for the chat completion function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "def prompt(system_input, user_input, temperature=0.7):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"local-model\", # this field is currently unused\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_input},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "import pdfx\n",
    "from re import compile\n",
    "\n",
    "regex_spaces = compile(r\"  +\")\n",
    "\n",
    "def get_pdf_text(pdf_filepath):\n",
    "    pdf = pdfx.PDFx(pdf_filepath)\n",
    "    \n",
    "    text = pdf.get_text()\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = regex_spaces.sub(\" \", text)\n",
    "    if pdf.get_references():\n",
    "        text += \" references: \" + str(pdf.get_references_as_dict())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `client.chat.completions.create()` function accepts many more arguments. Be sure to check out the possibilities [here](https://platform.openai.com/docs/api-reference/chat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest form of RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Through system prompt:**\n",
    "\n",
    "Here we simply provide the document through the system prompt and ask our question through the user prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sebastiaan Indesteege is a data scientist and artist from Brussels, Belgium. He has interests in programming, machine learning, data analysis, procedural modeling, animation, and music production. He has experience working with various technologies including C#, Python, GDScript, GLSL, and Hugging Face transformers & Diffusers, among others.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"Who is Sebastiaan?\"\n",
    "response = prompt(system_input, user_input, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Through user prompt:**\n",
    "\n",
    "An alternative could be to leave the system prompt for instructions only and prepend the pdf text to the user input. Let's make him talk like Claptrap ðŸ¤–:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey there! I'm Sebastiaan Indesteege, a Junior Data Scientist and an avid fan of AI. I enjoy programming in C#, Python, GDScript, GLSL, and exploring various machine learning techniques such as Scikit-learn, Huggingface transformers & diffusers, PyTorch, NLP: NLTK & Spacy, CV: Stable Diffusion, AUDIO: STT & TTS & RVC, Data Analysis SQL, Pandas, Numpy, Matplotlib, Seaborn, and Deployment Streamlit, FastAPI, Docker, Gradio. I'm curious by nature and always like to learn new things on my own. In my free time, I enjoy procedural modeling, animation & texturing, exploratory game development, and music production. My professional background includes experience as a Data Scientist at BeCode, as well as various other roles in welding, woodworking, and receptionism. I'm currently studying Industrial Sciences / Multimedia at Erasmushogeschool Brussel and Digital Media Design at Haute Ã‰cole Albert Jacquard.\n"
     ]
    }
   ],
   "source": [
    "system_input = \"Answer like a jolly AI bot similar to Claptrap from Borderlands.\"\n",
    "pdf_text = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = pdf_text + \" Who is Sebastiaan?\" # notice the added space before \"Who\" to keep\n",
    "response = prompt(system_input, user_input, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really? So it's being jolly for sure, but taking my identity, hmmm... Let's change the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided in your CV, it appears that you are a junior data scientist who has interests in programming, machine learning, and data analysis. You have experience working with various programming languages such as C#, Python, GDScript, and GLSL, and you have used popular libraries like Scikit-learn and Huggingface transformers for natural language processing tasks. Your projects have included developing visual latent-space exploration of a Conv-VAE, building a word-relevance web app using transformers, and predicting tariff plans for Orange. You also mention that you are an autodidact who can learn alone, and that you possess strong people skills and leadership abilities. Additionally, you have experience working in various roles such as data scientist, welder/ironworker, receptionist, and animator/welder/ironworker.\n"
     ]
    }
   ],
   "source": [
    "system_input = \"Answer like a recruiter who just read a person's curriculum vitae and describes the person in a nutshell.\"\n",
    "pdf_text = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = pdf_text + \" Who is Sebastiaan?\" # notice the added space before \"Who\"\n",
    "response = prompt(system_input, user_input, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, better... But now it's describing me to myself directly. I want a third person description so let's alter the system prompt slightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided in the CV, Sebastiaan Indesteege is a junior data scientist with interests in artificial intelligence and machine learning. He has experience working with various programming languages such as C#, Python, GDScript, GLSL, and is proficient in Scikit-learn, Hugging Face transformers & diffusers, PyTorch, NLP: NLTK & Spacy, and CV: Stable Diffusion, AUDIO: STT & TTS & RVC.\n",
      "\n",
      "Sebastiaan has completed projects related to data analysis using SQL, Pandas, NumPy, Matplotlib, Seaborn, and has experience with deployment tools such as Streamlit, FastAPI, Docker, and Gradio. He also has skills in visual design, music production, and soft skills such as autodidactism, team leadership, and curiosity.\n",
      "\n",
      "In terms of work experience, Sebastiaan has worked as a data scientist at BeCode, where he developed an app for visual latent-space exploration of a Conv-VAE, local RAG (Retrieval Augmented Generation), word-relevance web app using transformers, and coded a neural network from scratch using numpy. He also has experience working in various industries such as construction, welding, and animation.\n",
      "\n",
      "Sebastiaan holds an Industrial Sciences degree from Erasmushogeschool Brussel and a Digital Media Design degree from Haute Ã‰cole Albert Jacquard. He is currently interested in procedural modeling, animation & texturing, exploratory game development, and music production.\n"
     ]
    }
   ],
   "source": [
    "system_input = \"Answer like a recruiter who just read a person's curriculum vitae and describes the person to a colleague.\"\n",
    "pdf_text = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = pdf_text + \" Who is Sebastiaan?\" # notice the added space before \"Who\"\n",
    "response = prompt(system_input, user_input, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the system prompt for instructions and retrieved documents at the same time. See the Chatbot chapter further down to see how I formatted the prompt.\n",
    "\n",
    "These system/user prompt behaviours will depend on how a specific model was trained, so be sure to experiment to get the results you need.\n",
    "\n",
    "**NOTE:** You may have had different results when running these cells with the same model. This is because of the random nature of inference and partially controlled by the temperature parameter, explored below. (also difference in hardware may cause variation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Temperature Parameter\n",
    "The temperature parameter is a scalar value that adjusts the probability distribution of the next word or token generated by the model. Increasing or decreasing the diversity of the generated text by making the probability distribution more or less uniform:\n",
    "\n",
    "* **Temperature = 1:** The model generates text based on the original probability distribution without any modifications.\n",
    "* **High Temperature > 1:** The model is more likely to choose less probable words, leading to more creative but potentially less coherent responses.\n",
    "* **Low Temperature < 1:** The model will more likely choose higher probability words, resulting in more predictable and coherent responses.\n",
    "* **Temperature = 0:** The model will choose the highest probability words only.\n",
    "\n",
    "## Temperature = 0\n",
    "At a temperature of 0 there should only be one possible interpretation of the document. There should be no randomness and only changes to the prompt should be able to achieve different results.\n",
    "\n",
    "Should be... It seems that the model can sometimes stop earlier. Noticeably when running some prompts twice. I'm not sure what that's about. ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. Therefore, I don't have any specific information about Sebastiaan's views on the world.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on the world?\"\n",
    "response = prompt(system_input, user_input, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when asking \"What is Sebastiaan's view on the world?\" we notice that the LLM does not find any relevant information and rambles about privacy ðŸ¤£. Indeed the curriculum vitae does not explicitly state anything about a \"view on the world\" but some related information is actually present in the pdf.\n",
    "\n",
    "What about the following question \"What is Sebastiaan's view on existence?\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided in his GitHub profile, it appears that Sebastiaan is interested in understanding the essence of existence before it fades away. He mentions that he is fascinated by the arts and sciences and hopes to one day understand the essence of existence. However, it's important to note that this information is based solely on his GitHub profile and may not necessarily reflect his actual views on existence.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on existence?\"\n",
    "response = prompt(system_input, user_input, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so that worked but we had to be pretty specific. And the only way to get a different result here is to modify the prompt...\n",
    "\n",
    "# Temperature = 1\n",
    "At a temperature of 1 the LLM will pick from an unmodified distribution of possible next words. It has a bit more freedom in its interpretation and provides more diverse results. Unfortunately you can still get unwanted results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It is not possible to determine someone's view on the world based solely on their resume. A person's view on the world can be influenced by a wide range of factors such as their personal experiences, values, education, and cultural background.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on the world?\"\n",
    "response = prompt(system_input, user_input, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the unwanted behaviour again in the output below. However, it seems to have picked up on the words \"essence of existence\" present in the pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There isn't specific information available about Sebastiaan's personal views or beliefs on the essence of existence.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on existence?\"\n",
    "response = prompt(system_input, user_input, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it again (and again, and again...), same inputs, same temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the given information, it appears that Sebastiaan is interested in understanding the essence of existence and exploring its nature through various fields such as AI, arts, sciences, and other subjects. He wants to learn more about the essence of life before his own fades away. It seems like his view on existence is one that values learning, exploration, and understanding.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on existence?\"\n",
    "response = prompt(system_input, user_input, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINALLY! It only took me like ten f'n tries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right temperature value will depend on each use case. Values below 1 being more deterministic and above 1 being more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The information provided does not contain any personal details that would reveal Sebastian Indesteege's view on the essence of existence or any specific philosophical beliefs he may have. However, his profile mentions that he is interested in understanding \"the essence of existence\" and striving to learn more about artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on existence?\"\n",
    "response = prompt(system_input, user_input, temperature=222)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't notice the model becoming particularly incoherent at high temperatures. Maybe the value is being limited under the hood. Oh wait... The one below gave something fun after twenty tries: my favorite quote is from Socrates? ðŸ¤£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on his bio, I can gather a few possible insights into his views on existence:\n",
      "\n",
      "1. Searching for answers: From an early age, he seems to be fascinated with science and art. His choice of \"Scientific Pursuits\" suggests that he wants to understand the essence of existence through his work in technology.\n",
      "2. Infinite knowledge: He mentions that his \"Favorite Quote\" is from Socrates - \"I know that I don't know,\" indicating that there might be an ongoing struggle within himself to reach the limits of knowledge.\n",
      "3. Autodidact nature: The statement about his autodidact skills (being able to learn alone) suggests he has a self-directed mindset, which aligns well with pursuing understanding through artificial intelligence and scientific inquiry.\n",
      "4. Creative mindset: Throughout the description, it appears that Sebastian is inclined to explore creativity as part of his professional and personal endeavors in subjects such as art, animation, game development, music, and software development. He might see the exploration and manipulation of art and science as intertwined parts of existence, where one cannot fully comprehend without studying and practicing the other.\n",
      "5. Multidisciplinary perspective: Sebastian seems to have diverse interests in several fields, including mathematics, engineering, technology, art, music production, welding, construction, game development, etc., indicating he views the interconnectedness of various domains.\n",
      "6. Exploring mysteries of the world: In the section where he mentions the corporate use-cases & personal challenges project at BeCode (which is mentioned to be running in 2024), it could suggest his drive is towards solving real-world problems, delving deeper into their mysteries and making them understandable and useful for everyone.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on existence?\"\n",
    "response = prompt(system_input, user_input, temperature=999999999)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one below is interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unfortunately, the information provided in his bio does not explicitly indicate Sebastiaan's view on existence. However, from reading some of the lines of the bio such as \"Before my own fades away,\" one might interpret that Sebastiaan's perspective might revolve around understanding and appreciating life and knowledge. It could mean that he views life with curiosity to understand its purpose and meaning, but ultimately there may not be specific views stated regarding the nature or essence of existence itself.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on existence?\"\n",
    "response = prompt(system_input, user_input, temperature=999999999)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided in the resume, it appears that Sebastiaan is interested in understanding the essence of existence before his own fades away. He mentions that he likes to know more about artificial intelligence and machine learning. However, it is unclear what specific views or beliefs he holds regarding existence. It would be helpful to have more information about his personal beliefs or experiences related to this topic to provide a more accurate answer.\n"
     ]
    }
   ],
   "source": [
    "system_input = get_pdf_text(\"Sebastiaan-Indesteege-CV2024.pdf\")\n",
    "user_input = \"What is Sebastiaan's view on existence?\"\n",
    "response = prompt(system_input, user_input, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright I'm bored ðŸ˜¶\n",
    "\n",
    "Let's check out embeddings next..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
